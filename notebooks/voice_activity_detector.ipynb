{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Ctrl+C to stop.\n",
      "Stopped recording.\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "audio_queue = queue.Queue()\n",
    "sample_rate = 16000\n",
    "frame_duration = 0.02  # 20 ms\n",
    "frame_size = int(sample_rate * frame_duration)\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    mono_data = indata.copy()\n",
    "    audio_queue.put(mono_data)\n",
    "\n",
    "# Open the microphone stream\n",
    "with sd.InputStream(channels=1, samplerate=sample_rate, blocksize=frame_size, callback=callback):\n",
    "    print(\"Recording...\")\n",
    "    try:\n",
    "        while True:\n",
    "            frame = audio_queue.get()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped recording.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio.pipelines import VoiceActivityDetection\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6b8c8ccca8451ba616cdacd6eb0df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Максим\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Максим\\.cache\\torch\\pyannote\\models--pyannote--segmentation. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94e17988b0b4e5589d1c6101438091c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/318 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Максим\\.cache\\torch\\pyannote\\models--pyannote--segmentation\\snapshots\\660b9e20307a2b0cdb400d0f80aadc04a701fc54\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.5.1+cpu. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "pipeline = VoiceActivityDetection(segmentation=\"pyannote/segmentation\", use_auth_token=\"TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Ctrl+C to stop.\n",
      "[ 00:00:00.756 -->  00:00:01.026] A SPEECH\n",
      "[ 00:00:00.030 -->  00:00:01.026] A SPEECH\n",
      "\n",
      "[ 00:00:00.030 -->  00:00:00.672] A SPEECH\n",
      "[ 00:00:00.554 -->  00:00:01.026] A SPEECH\n",
      "\n",
      "Stopped recording.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "accumulator = np.array([], dtype=np.float32)\n",
    "accumulation_window = 1.0  # 1 second\n",
    "samples_per_window = int(sample_rate * accumulation_window)\n",
    "\n",
    "with sd.InputStream(device=1, channels=1, samplerate=sample_rate, blocksize=frame_size, callback=callback):\n",
    "    print(\"Recording... Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        while True:\n",
    "            frame = audio_queue.get()\n",
    "            accumulator = np.concatenate((accumulator, frame.flatten()))\n",
    "            if len(accumulator) >= samples_per_window:\n",
    "                chunk = accumulator[:samples_per_window]\n",
    "                accumulator = accumulator[samples_per_window:]\n",
    "                waveform = torch.tensor(chunk, dtype=torch.float32).unsqueeze(0)\n",
    "                vad_result = pipeline({\"waveform\": waveform, \"sample_rate\": sample_rate})\n",
    "                print(vad_result)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped recording.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "print(sd.query_devices())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
